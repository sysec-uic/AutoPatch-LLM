{
    "appName": "LLM Dispatch",
    "appVersion": "0.1.0",
    "appDescription": "A system for managing and dispatching requests to various language models.",
    "systemprompt_full_patch": "/workspace/AutoPatch-LLM/src/llm-dispatch/data/prompts/system_prompt.txt",
    "userprompt_full_path": "/workspace/AutoPatch-LLM/src/llm-dispatch/data/prompts/user_prompt.txt",
    "default_model": "gpt-3.5-turbo",
    "default_api_provider": "openai",
    "default_in_memory_provider": "openai",
    "default_model_settings": {
        "max_tokens": 4096,
        "temperature": 0.7,
        "top_p": 1,
        "frequency_penalty": 0,
        "presence_penalty": 0,
        "stop": null
    },
    "mqtt" : {
        "enabled": true,
        "broker_host": "mqtt",
        "broker_port": 1883,
        "topics": {
            "request": "llm/dispatch/request",
            "response": "llm/dispatch/response",
            "error": "llm/dispatch/error"
        },
        "client_id": "autopatch-llm-dispatch-client",
        "username": null,
        "password": null,
        "keepalive": 60,
        "tls": {
            "enabled": false,
            "ca_certs": null,
            "certfile": null,
            "keyfile": null
        }
    },
    "api": {
        "base_url": "https://api.llm-dispatch.com/v1",
        "timeout": 30,
        "retry_attempts": 3,
        "retry_delay": 2000
    },
    "logging": {
        "level": "info",
        "log_file": "/var/log/llm-dispatch.log",
        "log_format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    },
    "cache": {
        "enabled": true,
        "cache_dir": "/var/cache/llm-dispatch",
        "cache_expiration": 3600
    },
    "model_router": {
        "enabled": true,
        "fallback_model": "google/gemini-2.5-pro-exp-03-25:free",
        "max_concurrent_requests": 5,
        "base_url": "https://openrouter.ai/api/v1",
        "timeout": 30,
        "retry_attempts": 3,
        "retry_delay": 2000
    },
    "models": [
        {
            "gpt-3.5-turbo": {
                "id": "gpt-3.5-turbo",
                "name": "GPT-3.5 Turbo",
                "description": "A powerful language model by OpenAI, suitable for a wide range of tasks.",
                "model": "gpt-3.5-turbo",
                "max_tokens": 4096,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_openai_api_key",
                    "api_base": "https://api.openai.com/v1",
                    "api_type": "openai"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/gpt-3.5-turbo/model",
                    "api_type": "openai"
                }
            }
        },
        {
            "gpt-4": {
                "id": "gpt-4o-mini",
                "name": "GPT-4o Mini",
                "description": "The latest and most advanced language model by OpenAI, capable of understanding and generating human-like text.",
                "model": "gpt-4o-mini",
                "max_tokens": 8192,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_openai_api_key",
                    "api_base": "https://api.openai.com/v1",
                    "api_type": "openai",
                    "openrouter_tag": "openai/gpt-4o-mini:free"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/gpt-4/model",
                    "api_type": "openai"
                }
            }
        },
        {
            "llama2": {
                "id": "llama2",
                "name": "Llama 2",
                "description": "A state-of-the-art language model developed by Meta, optimized for various NLP tasks.",
                "model": "llama2",
                "max_tokens": 4096,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_llama2_api_key",
                    "api_base": "https://your_llama2_endpoint/",
                    "api_type": "llama2"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/llama2/model",
                    "api_type": "llama2"
                }
            }
        },
        {
            "mistral": {
                "id": "mistral",
                "name": "Mistral",
                "description": "A high-performance language model designed for efficiency and speed.",
                "model": "mistral",
                "max_tokens": 4096,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_mistral_api_key",
                    "api_base": "https://your_mistral_endpoint/",
                    "api_type": "mistral"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/mistral/model",
                    "api_type": "mistral"
                }
            }
        },
        {
            "claude": {
                "id": "claude",
                "name": "Claude",
                "description": "A language model by Anthropic, designed with safety and alignment in mind.",
                "model": "claude",
                "max_tokens": 4096,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_claude_api_key",
                    "api_base": "https://your_claude_endpoint/",
                    "api_type": "claude"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/claude/model",
                    "api_type": "claude"
                }
            }
        },
        {
            "deepseek": {
                "id": "deepseek",
                "name": "DeepSeek",
                "description": "A language model optimized for deep learning tasks and research.",
                "model": "deepseek",
                "max_tokens": 4096,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_deepseek_api_key",
                    "api_base": "https://your_deepseek_endpoint/",
                    "api_type": "deepseek/deepseek-r1-zero:free"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/deepseek/model",
                    "api_type": "deepseek"
                }
            }
        },
        {
            "gemini": {
                "id": "gemini",
                "name": "Gemini",
                "description": "A language model by Google, designed for advanced natural language understanding.",
                "model": "gemini",
                "max_tokens": 4096,
                "temperature": 0.7,
                "top_p": 1,
                "frequency_penalty": 0,
                "presence_penalty": 0,
                "stop": null,
                "api_provider": {
                    "api_key": "your_google_api_key",
                    "api_base": "https://your_google_endpoint/",
                    "api_type": "google",
                    "openrouter_tag": "google/gemini-2.0-flash-lite-preview-02-05:free"
                },
                "in_memory_provider": {
                    "model_path": "/path/to/gemini/model",
                    "api_type": "gemini"
                }
            }
        }
    ]
}