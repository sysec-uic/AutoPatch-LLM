Final Report
For the final project we chose to have multiple LLMs analyze code for memory errors.  During our initial discussion we decided to have a very structured approach. We needed to make sure that this idea was feasible. Robert had picked three memory related bug types and I searched online to find simple and very obvious examples of those memory bugs. We also agreed on having two LLMs analyze our data: ChatGPT4o and LLAMA_3_1. This decision was made because they both have easily accessible models with a large cap of responses. 
	From work experience I knew the best place to search was to go to cwe.mitre.org and search for the three types. CWE stands for Common Weakness Enumeration, and it is a collection of all the different types of weaknesses in code. It has exactly the type of elementary examples with explanations we were looking for. So, I gathered a few of each type and pushed it to Github. Then I asked ChatGPT4o about each and compared the answers to make sure that the LLM was able to recognize the errors. It is important to state that each time I fed questions into the model, I made sure to clear the memory and the chat logs as to not create any feedback loop. 
	Having confirmed our sample, I went to find five real examples of each type. I went to cve.mitre.org which stands for Common Vulnerabilities and Exposures and searched for each type. I noted that the buffer overflow was the most prevalent with over sixteen thousand records. This site is valuable not only because it gave plenty of references and assigned each one a score but also gave each a vector string which classified it (example:CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H). 
	One of my main difficulties was finding the site mentioned above and getting references to sites where I was able to find the actual vulnerability. One of my main goals was to get a wide range of vulnerabilities. I wanted to get a few examples from each decade but that turned out to be difficult. For older vulnerabilities, majority of references point to websites that either no longer exist or ger redirected to the main page.  For newer ones, I was restricted by the website from viewing any parts due to security complications of it still being exploited. I spend much time trying to get any sample code for (CVE-2024-0012) affecting Palo Alto Networks PAN-OS Software, which came out as a 9.8 score and was widely talked about in security circles, but I was unsuccessful. I did, however, find much more luck in open source projects where the bugs were clearly shown and I had access to the entire program file. 
	With that discovery I chose to pick majority of the memory bugs from 2024, to further the point that these are still extremely prevalent and that a LLM can detect and remediate them. I then collected five sample of each and stored them in our Github repository. 	
	Next, I wanted to get the actual responses from each model. I again cleared all memory in my LLM and first prompted it to look for those memory bugs and then fed it the code and recorded it. 
	One of our goals was to create an API that would automatically send a request to the LLM. My goal was to get a LLAMA model uploaded to AWS like I did in my other class CS441 where I created my own LLM and host it at dawidbiel.com (trained on 150KB of corpus). I was unable to complete that goal as AWS would significantly throttle my download speeds and estimated that the 8-15GB model would take weeks to complete. 
	After I gathered all the responses, I compared them using metrics we defined such as accuracy, solution quality, comprehensibility etc. I ensured that while I was gathering I codenamed each LLM so that I would not have a bias when reading the responses. The responses were very different in their analysis. ChatGPT4o was very structured in its response approach in that it first identified the issue, then suggested fixes, showed affected code, showed revised code, gave improvements, as well as a summary. LLAMA on the other hand had everything in a paragraph writeup and sometimes it gave the full corrected code. Overall, ChatGPT4o was much better at recognizing the vulnerabilities and implementing fixes. It also shined when it came to longer code. I specifically chose a longer piece of code and LLAMA was unable to process it, while ChatGPT4o recognized the bug. LLAMA only shined when it came to its references at the end which ChatGPT4o did not include. We did not specifically ask it to provide them, but it was interesting to see it give them to us. 
	What I found particularly useful from ChatGPT4o is that it specifically identified the line where the bug is. With our prompt it is very consistent with its responses, so an API call to that LLM from an IDE can be a future project where if it recognizes memory problems it can give a small popup.